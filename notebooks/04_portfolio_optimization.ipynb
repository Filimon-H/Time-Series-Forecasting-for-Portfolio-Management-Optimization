{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Task 4: Portfolio Optimization Based on Forecast\n",
                "\n",
                "## Objective\n",
                "Use insights from the TSLA forecast (Task 3) to construct an optimal portfolio using Modern Portfolio Theory (MPT).\n",
                "\n",
                "## Assets\n",
                "- **TSLA**: Expected return from forecast model\n",
                "- **BND**: Historical average return (bond stability)\n",
                "- **SPY**: Historical average return (market exposure)\n",
                "\n",
                "## Deliverables\n",
                "- Efficient Frontier plot with key portfolios marked\n",
                "- Covariance matrix visualization (heatmap)\n",
                "- Final portfolio recommendation with weights and metrics\n",
                "- Written justification for portfolio selection"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Imports and Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import joblib\n",
                "\n",
                "from pypfopt import EfficientFrontier, risk_models, expected_returns\n",
                "from pypfopt import plotting\n",
                "\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "pd.set_option('display.float_format', '{:.4f}'.format)\n",
                "\n",
                "# Constants\n",
                "TRADING_DAYS = 252\n",
                "RISK_FREE_RATE = 0.02  # 2% annual risk-free rate\n",
                "\n",
                "print('Setup complete!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load price data\n",
                "prices = pd.read_csv('../data/processed/adj_close_prices.csv', parse_dates=['Date'], index_col='Date')\n",
                "prices = prices.sort_index()\n",
                "\n",
                "# Ensure we have all three assets\n",
                "tickers = ['TSLA', 'BND', 'SPY']\n",
                "prices = prices[tickers].dropna()\n",
                "\n",
                "print(f'Price data: {prices.index.min().date()} to {prices.index.max().date()}')\n",
                "print(f'Shape: {prices.shape}')\n",
                "prices.tail()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate daily returns\n",
                "daily_returns = prices.pct_change().dropna()\n",
                "\n",
                "print('Daily Returns Statistics:')\n",
                "daily_returns.describe()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load forecast metrics from Task 3\n",
                "forecast_metrics = joblib.load('../data/processed/models/tsla_forecast_metrics.joblib')\n",
                "\n",
                "print('TSLA Forecast Metrics from Task 3:')\n",
                "for key, value in forecast_metrics.items():\n",
                "    print(f'  {key}: {value}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Prepare Expected Returns\n",
                "\n",
                "- **TSLA**: Use forecasted return from Task 3\n",
                "- **BND, SPY**: Use historical average returns (annualized)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TSLA: Forecasted annual return (from 12-month forecast)\n",
                "tsla_expected_return = forecast_metrics['return_12m_pct'] / 100  # Convert from percentage\n",
                "\n",
                "# BND and SPY: Historical annualized returns\n",
                "hist_mean_daily = daily_returns[['BND', 'SPY']].mean()\n",
                "hist_annual_returns = (1 + hist_mean_daily) ** TRADING_DAYS - 1\n",
                "\n",
                "# Create expected returns vector\n",
                "mu = pd.Series({\n",
                "    'TSLA': tsla_expected_return,\n",
                "    'BND': hist_annual_returns['BND'],\n",
                "    'SPY': hist_annual_returns['SPY']\n",
                "})\n",
                "\n",
                "print('=' * 50)\n",
                "print('EXPECTED ANNUAL RETURNS')\n",
                "print('=' * 50)\n",
                "for ticker, ret in mu.items():\n",
                "    source = 'Forecast' if ticker == 'TSLA' else 'Historical'\n",
                "    print(f'{ticker}: {ret*100:+.2f}% ({source})')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Compute Covariance Matrix"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate sample covariance matrix (annualized)\n",
                "cov_daily = daily_returns[tickers].cov()\n",
                "cov_annual = cov_daily * TRADING_DAYS\n",
                "\n",
                "print('Annualized Covariance Matrix:')\n",
                "cov_annual"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Correlation matrix for interpretation\n",
                "corr_matrix = daily_returns[tickers].corr()\n",
                "\n",
                "print('Correlation Matrix:')\n",
                "corr_matrix"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Covariance heatmap (deliverable)\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# Covariance\n",
                "sns.heatmap(cov_annual, annot=True, fmt='.4f', cmap='YlOrRd', ax=axes[0],\n",
                "            annot_kws={'size': 12, 'weight': 'bold'})\n",
                "axes[0].set_title('Annualized Covariance Matrix', fontsize=12, fontweight='bold')\n",
                "\n",
                "# Correlation\n",
                "sns.heatmap(corr_matrix, annot=True, fmt='.3f', cmap='RdYlGn', center=0, ax=axes[1],\n",
                "            vmin=-1, vmax=1, annot_kws={'size': 12, 'weight': 'bold'})\n",
                "axes[1].set_title('Correlation Matrix', fontsize=12, fontweight='bold')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../data/processed/covariance_heatmap.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print('Covariance heatmap saved!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Portfolio Optimization (Efficient Frontier)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Maximum Sharpe Ratio Portfolio\n",
                "ef_sharpe = EfficientFrontier(mu, cov_annual)\n",
                "weights_sharpe = ef_sharpe.max_sharpe(risk_free_rate=RISK_FREE_RATE)\n",
                "cleaned_weights_sharpe = ef_sharpe.clean_weights()\n",
                "perf_sharpe = ef_sharpe.portfolio_performance(verbose=False, risk_free_rate=RISK_FREE_RATE)\n",
                "\n",
                "print('=' * 50)\n",
                "print('MAXIMUM SHARPE RATIO PORTFOLIO')\n",
                "print('=' * 50)\n",
                "print('\\nWeights:')\n",
                "for ticker, weight in cleaned_weights_sharpe.items():\n",
                "    print(f'  {ticker}: {weight*100:.1f}%')\n",
                "print(f'\\nExpected Annual Return: {perf_sharpe[0]*100:.2f}%')\n",
                "print(f'Annual Volatility: {perf_sharpe[1]*100:.2f}%')\n",
                "print(f'Sharpe Ratio: {perf_sharpe[2]:.3f}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Minimum Volatility Portfolio\n",
                "ef_minvol = EfficientFrontier(mu, cov_annual)\n",
                "weights_minvol = ef_minvol.min_volatility()\n",
                "cleaned_weights_minvol = ef_minvol.clean_weights()\n",
                "perf_minvol = ef_minvol.portfolio_performance(verbose=False, risk_free_rate=RISK_FREE_RATE)\n",
                "\n",
                "print('=' * 50)\n",
                "print('MINIMUM VOLATILITY PORTFOLIO')\n",
                "print('=' * 50)\n",
                "print('\\nWeights:')\n",
                "for ticker, weight in cleaned_weights_minvol.items():\n",
                "    print(f'  {ticker}: {weight*100:.1f}%')\n",
                "print(f'\\nExpected Annual Return: {perf_minvol[0]*100:.2f}%')\n",
                "print(f'Annual Volatility: {perf_minvol[1]*100:.2f}%')\n",
                "print(f'Sharpe Ratio: {perf_minvol[2]:.3f}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Generate and Plot Efficient Frontier"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate efficient frontier points\n",
                "def generate_efficient_frontier(mu, cov, n_points=100):\n",
                "    \"\"\"Generate points along the efficient frontier.\"\"\"\n",
                "    returns = []\n",
                "    volatilities = []\n",
                "    \n",
                "    # Get return range\n",
                "    ef_temp = EfficientFrontier(mu, cov)\n",
                "    ef_temp.min_volatility()\n",
                "    min_ret = ef_temp.portfolio_performance()[0]\n",
                "    max_ret = mu.max()\n",
                "    \n",
                "    target_returns = np.linspace(min_ret, max_ret * 0.95, n_points)\n",
                "    \n",
                "    for target in target_returns:\n",
                "        try:\n",
                "            ef = EfficientFrontier(mu, cov)\n",
                "            ef.efficient_return(target)\n",
                "            ret, vol, _ = ef.portfolio_performance()\n",
                "            returns.append(ret)\n",
                "            volatilities.append(vol)\n",
                "        except:\n",
                "            continue\n",
                "    \n",
                "    return np.array(volatilities), np.array(returns)\n",
                "\n",
                "frontier_vol, frontier_ret = generate_efficient_frontier(mu, cov_annual)\n",
                "print(f'Generated {len(frontier_vol)} efficient frontier points')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot Efficient Frontier (main deliverable)\n",
                "fig, ax = plt.subplots(figsize=(12, 8))\n",
                "\n",
                "# Plot efficient frontier\n",
                "ax.plot(frontier_vol * 100, frontier_ret * 100, 'b-', linewidth=2, label='Efficient Frontier')\n",
                "\n",
                "# Plot individual assets\n",
                "asset_vols = np.sqrt(np.diag(cov_annual)) * 100\n",
                "asset_rets = mu * 100\n",
                "colors = {'TSLA': 'red', 'BND': 'green', 'SPY': 'orange'}\n",
                "for i, ticker in enumerate(tickers):\n",
                "    ax.scatter(asset_vols[i], asset_rets.iloc[i], s=150, c=colors[ticker], \n",
                "               marker='o', label=ticker, zorder=5, edgecolors='black')\n",
                "\n",
                "# Mark Max Sharpe portfolio\n",
                "ax.scatter(perf_sharpe[1] * 100, perf_sharpe[0] * 100, s=300, c='gold', \n",
                "           marker='*', label=f'Max Sharpe (SR={perf_sharpe[2]:.2f})', zorder=6, edgecolors='black')\n",
                "\n",
                "# Mark Min Volatility portfolio\n",
                "ax.scatter(perf_minvol[1] * 100, perf_minvol[0] * 100, s=300, c='cyan', \n",
                "           marker='D', label=f'Min Volatility', zorder=6, edgecolors='black')\n",
                "\n",
                "# Capital Market Line (from risk-free to max Sharpe)\n",
                "cml_x = np.linspace(0, perf_sharpe[1] * 100 * 1.5, 50)\n",
                "cml_y = RISK_FREE_RATE * 100 + perf_sharpe[2] * cml_x\n",
                "ax.plot(cml_x, cml_y, 'k--', linewidth=1, alpha=0.5, label='Capital Market Line')\n",
                "\n",
                "ax.set_xlabel('Annual Volatility (%)', fontsize=12)\n",
                "ax.set_ylabel('Expected Annual Return (%)', fontsize=12)\n",
                "ax.set_title('Efficient Frontier with Optimal Portfolios', fontsize=14, fontweight='bold')\n",
                "ax.legend(loc='upper left', fontsize=10)\n",
                "ax.grid(True, alpha=0.3)\n",
                "ax.set_xlim(0, max(asset_vols) * 1.1)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../data/processed/efficient_frontier.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print('Efficient Frontier plot saved!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Portfolio Comparison Table"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create comparison table\n",
                "comparison = pd.DataFrame({\n",
                "    'Max Sharpe': {\n",
                "        'TSLA Weight': f\"{cleaned_weights_sharpe['TSLA']*100:.1f}%\",\n",
                "        'BND Weight': f\"{cleaned_weights_sharpe['BND']*100:.1f}%\",\n",
                "        'SPY Weight': f\"{cleaned_weights_sharpe['SPY']*100:.1f}%\",\n",
                "        'Expected Return': f\"{perf_sharpe[0]*100:.2f}%\",\n",
                "        'Volatility': f\"{perf_sharpe[1]*100:.2f}%\",\n",
                "        'Sharpe Ratio': f\"{perf_sharpe[2]:.3f}\"\n",
                "    },\n",
                "    'Min Volatility': {\n",
                "        'TSLA Weight': f\"{cleaned_weights_minvol['TSLA']*100:.1f}%\",\n",
                "        'BND Weight': f\"{cleaned_weights_minvol['BND']*100:.1f}%\",\n",
                "        'SPY Weight': f\"{cleaned_weights_minvol['SPY']*100:.1f}%\",\n",
                "        'Expected Return': f\"{perf_minvol[0]*100:.2f}%\",\n",
                "        'Volatility': f\"{perf_minvol[1]*100:.2f}%\",\n",
                "        'Sharpe Ratio': f\"{perf_minvol[2]:.3f}\"\n",
                "    }\n",
                "})\n",
                "\n",
                "print('=' * 60)\n",
                "print('PORTFOLIO COMPARISON')\n",
                "print('=' * 60)\n",
                "print(comparison.to_string())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Final Portfolio Recommendation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Recommend Max Sharpe portfolio (best risk-adjusted returns)\n",
                "recommended_weights = cleaned_weights_sharpe\n",
                "recommended_perf = perf_sharpe\n",
                "recommendation_type = 'Maximum Sharpe Ratio'\n",
                "\n",
                "print('=' * 60)\n",
                "print('FINAL PORTFOLIO RECOMMENDATION')\n",
                "print('=' * 60)\n",
                "print(f'\\nRecommended Portfolio: {recommendation_type}')\n",
                "print('\\n--- Optimal Weights ---')\n",
                "for ticker, weight in recommended_weights.items():\n",
                "    print(f'  {ticker}: {weight*100:.1f}%')\n",
                "print('\\n--- Expected Performance ---')\n",
                "print(f'  Expected Annual Return: {recommended_perf[0]*100:.2f}%')\n",
                "print(f'  Expected Volatility:    {recommended_perf[1]*100:.2f}%')\n",
                "print(f'  Sharpe Ratio:           {recommended_perf[2]:.3f}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Portfolio weights visualization\n",
                "fig, ax = plt.subplots(figsize=(8, 8))\n",
                "\n",
                "weights_list = [recommended_weights[t] for t in tickers]\n",
                "colors_list = [colors[t] for t in tickers]\n",
                "\n",
                "wedges, texts, autotexts = ax.pie(\n",
                "    weights_list, \n",
                "    labels=tickers, \n",
                "    autopct='%1.1f%%',\n",
                "    colors=colors_list,\n",
                "    explode=[0.02] * 3,\n",
                "    startangle=90,\n",
                "    textprops={'fontsize': 12, 'fontweight': 'bold'}\n",
                ")\n",
                "\n",
                "ax.set_title(f'Recommended Portfolio Allocation\\n({recommendation_type})', \n",
                "             fontsize=14, fontweight='bold')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../data/processed/portfolio_weights.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Written Justification"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "justification = f\"\"\"\n",
                "PORTFOLIO SELECTION JUSTIFICATION\n",
                "{'=' * 60}\n",
                "\n",
                "We recommend the Maximum Sharpe Ratio portfolio with the following allocation:\n",
                "TSLA ({recommended_weights['TSLA']*100:.1f}%), BND ({recommended_weights['BND']*100:.1f}%), \n",
                "and SPY ({recommended_weights['SPY']*100:.1f}%).\n",
                "\n",
                "This portfolio is selected because it offers the highest risk-adjusted return \n",
                "(Sharpe Ratio of {recommended_perf[2]:.3f}) among all feasible portfolios on the \n",
                "efficient frontier. The expected annual return of {recommended_perf[0]*100:.2f}% \n",
                "with a volatility of {recommended_perf[1]*100:.2f}% represents an optimal trade-off \n",
                "between risk and reward.\n",
                "\n",
                "The allocation leverages the forecast-driven expected return for TSLA \n",
                "({forecast_metrics['return_12m_pct']:.1f}% over 12 months) while using BND for \n",
                "stability and SPY for broad market exposure. The low correlation between BND \n",
                "and the equity positions (TSLA, SPY) provides diversification benefits that \n",
                "reduce overall portfolio risk without sacrificing expected returns.\n",
                "\n",
                "For investors with lower risk tolerance, the Minimum Volatility portfolio \n",
                "(volatility: {perf_minvol[1]*100:.2f}%) offers a more conservative alternative, \n",
                "though with reduced expected returns ({perf_minvol[0]*100:.2f}%).\n",
                "\"\"\"\n",
                "\n",
                "print(justification)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save portfolio recommendation for Task 5\n",
                "portfolio_recommendation = {\n",
                "    'weights': recommended_weights,\n",
                "    'expected_return': recommended_perf[0],\n",
                "    'volatility': recommended_perf[1],\n",
                "    'sharpe_ratio': recommended_perf[2],\n",
                "    'type': recommendation_type\n",
                "}\n",
                "joblib.dump(portfolio_recommendation, '../data/processed/models/portfolio_recommendation.joblib')\n",
                "\n",
                "# Also save comparison table\n",
                "comparison.to_csv('../data/processed/portfolio_comparison.csv')\n",
                "\n",
                "print('Portfolio recommendation saved for Task 5!')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print('\\n' + '=' * 60)\n",
                "print('TASK 4 COMPLETE')\n",
                "print('=' * 60)\n",
                "print('\\nDeliverables:')\n",
                "print('  ✓ Efficient Frontier plot with key portfolios marked')\n",
                "print('  ✓ Covariance matrix visualization (heatmap)')\n",
                "print('  ✓ Final portfolio recommendation with weights and metrics')\n",
                "print('  ✓ Written justification for portfolio selection')\n",
                "print('\\nSaved outputs:')\n",
                "print('  - data/processed/covariance_heatmap.png')\n",
                "print('  - data/processed/efficient_frontier.png')\n",
                "print('  - data/processed/portfolio_weights.png')\n",
                "print('  - data/processed/portfolio_comparison.csv')\n",
                "print('  - data/processed/models/portfolio_recommendation.joblib')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}